#+STARTUP: latexpreview
#+STARTUP: inlineimages


* The equation to solve:
\begin{equation}
\begin{aligned}
\begin{cases}
\label{eq:NS-n1}
\left[\frac{\partial{v}}{\partial{t}} + v\frac{\partial{v}}{\partial{x}} \right] = \frac{1}{\rho{}}\dfrac{\partial \left(\mu \frac{\partial{v}}{\partial{x}} \right)}{\partial{x}} - \left(\frac{c_0^2}{\rho{}}\right)\dfrac{\partial{\rho}}{\partial{x}} + \frac{V(\rho) - v}{\tau} \\\\
     \dfrac{\partial{\rho}}{\partial{t}} + \dfrac{\partial{\left( \rho{}v \right)}}{\partial{x}}=0
\end{cases}
   \end{aligned}
 \end{equation}

\begin{equation}
\begin{aligned}
q(x,t)=\rho(x,t)v(x,t)
\end{aligned}
\end{equation}

* Boundary Conditions:
\begin{equation}
\begin{aligned}
q(0,t) &= q(L,t)\\
v(0,t) &= v(L,t),\quad \dfrac{\partial{v}}{\partial{x}}\biggr\rvert_0 = \dfrac{\partial{v}}{\partial{x}}\biggr\rvert_L  
\end{aligned}
\end{equation}

From the definition of $q$ and the boundary condition (I),
\begin{equation}
\begin{aligned}
&\rho(0,t)v(0,t) = \rho(L,t)v(L,t) \\
&\implies \rho(0,t) = \rho(L,t)
\end{aligned}
\end{equation}

* Examples from NeuralPDE.jl
** System of PDEs

#+begin_src julia :session main :result output
  using NeuralPDE, Flux, ModelingToolkit, GalacticOptim, Optim, DiffEqFlux
  using Quadrature,Cubature
  import ModelingToolkit: Interval, infimum, supremum

  @parameters t, x
  @variables u1(..), u2(..), u3(..)
  Dt = Differential(t)
  Dtt = Differential(t)^2
  Dx = Differential(x)
  Dxx = Differential(x)^2

  eqs = [Dtt(u1(t,x)) ~ Dxx(u1(t,x)) + u3(t,x)*sin(pi*x),
         Dtt(u2(t,x)) ~ Dxx(u2(t,x)) + u3(t,x)*cos(pi*x),
         0. ~ u1(t,x)*sin(pi*x) + u2(t,x)*cos(pi*x) - exp(-t)]

  bcs = [u1(0,x) ~ sin(pi*x),
         u2(0,x) ~ cos(pi*x),
         Dt(u1(0,x)) ~ -sin(pi*x),
         Dt(u2(0,x)) ~ -cos(pi*x),
         u1(t,0) ~ 0.,
         u2(t,0) ~ exp(-t),
         u1(t,1) ~ 0.,
         u2(t,1) ~ -exp(-t)]


  # Space and time domains
  domains = [t ∈ Interval(0.0,1.0),
             x ∈ Interval(0.0,1.0)]

  # Neural network
  input_ = length(domains)
  n = 15
  chain =[FastChain(FastDense(input_,n,Flux.σ),FastDense(n,n,Flux.σ),FastDense(n,1)) for _ in 1:3]
  initθ = map(c -> Float64.(c), DiffEqFlux.initial_params.(chain))

  _strategy = QuadratureTraining()
  discretization = PhysicsInformedNN(chain, _strategy, init_params= initθ)

  pde_system = PDESystem(eqs,bcs,domains,[t,x],[u1,u2,u3])
  prob = discretize(pde_system,discretization)
  sym_prob = symbolic_discretize(pde_system,discretization)

  pde_inner_loss_functions = prob.f.f.loss_function.pde_loss_function.pde_loss_functions.contents
  bcs_inner_loss_functions = prob.f.f.loss_function.bcs_loss_function.bc_loss_functions.contents

  cb = function (p,l)
      println("loss: ", l )
      println("pde_losses: ", map(l_ -> l_(p), pde_inner_loss_functions))
      println("bcs_losses: ", map(l_ -> l_(p), bcs_inner_loss_functions))
      return false
  end

  res = GalacticOptim.solve(prob,BFGS(); cb = cb, maxiters=5000)

  phi = discretization.phi
#+end_src

#+RESULTS:

#+begin_src julia :session main :result output
xs,ys = [infimum(domain):dx/10:domain.domain.upper for domain in domains]
analytic_sol_func(x,y) = (sin(pi*x)*sin(pi*y))/(2pi^2)

u_predict = reshape([first(phi([x,y],res.minimizer)) for x in xs for y in ys],(length(xs),length(ys)))
u_real = reshape([analytic_sol_func(x,y) for x in xs for y in ys], (length(xs),length(ys)))
diff_u = abs.(u_predict .- u_real)

using Plots
p1 = plot(xs, ys, u_real, linetype=:contourf,title = "analytic");
p2 = plot(xs, ys, u_predict, linetype=:contourf,title = "predict");
p3 = plot(xs, ys, diff_u,linetype=:contourf,title = "error");
plot(p1,p2,p3)
#+end_src

#+RESULTS:

* Kerner - Car Flow

# Let $V(\rho)=1.5*(1-p/\hat{p})^2$, so $p \to \hat{\rho} \implies V(\hat{\rho}) \to 0$.
Let, $V(\rho) = v_h * (e^{-\frac{(\rho - \rho_h)}{\tau}}) + \delta{v}$.

#+begin_src julia :session main :result output :tangle neuralPDE.jl
  using NeuralPDE, Flux, ModelingToolkit, GalacticOptim, Optim, DiffEqFlux
  import ModelingToolkit: Interval, infimum, supremum
  import Flux: flatten, params
#+end_src

#+RESULTS:
: nothing

# #+begin_src julia :session main :result output
#   #V(ρ)=1.5*(1-ρ/2)²;
#   @parameters t, x, μ, c₀, τ, L, l
#   @variables v(..), ρ(..)
#   μ=0.3;
#   c₀= sqrt(5.5);
#   τ = 0.02;
#   l=0.08;
#   L = 100.0;
#   Dt = Differential(t)
#   Dx = Differential(x)
#   Dxx = Differential(x)^2
# #+end_src

# #+RESULTS:

 # $V(\rho) = v_h * (e^{-\frac{(\rho - \rho_h)}{\tau}}) + \delta{v}$

Let's put as a condition that
$[-1 -\frac{\rho_h}{c_0}\xi(\rho_h)]\rho_h>(\frac{2\pi{}l}{L})^2$ in which $\xi(\rho_h)= \dfrac{dV(\rho_h)}{dt}$

# \begin{equation}
# \begin{aligned}
# \dfrac{dV(\rho_h)}{dt}= \dfrac{v_h (\rho - \rho_h)}{\tau^2}(e^{-\frac{(\rho - \rho_h)}{\tau}})
# \end{aligned}
# \end{equation}

#+begin_src julia :session main :result output :tangle neuralPDE.jl
  @parameters t, x, N, L, ρ_hat, μ, c₀, τ, L, l,vₕ, k,m
  @variables v(..), ρ(..)
  ρ_hat=0.89;
  m=1;
  μ=1; #choose as we like
  τ=1; #choose as we like 
  l=sqrt(μ*τ/ρ_hat);

  N = 168; 
  ρₕ = 0.168;
  L=N/ρₕ; 
  δρ₀ = 0.02;
  vₕ = 5.0461*((1+exp((ρₕ-0.25)/0.06))^-1 - 3.72*10^-6);

  # ρₕ=N/L;
  k=2π/L;

  c₀= 1.8634; 
  Dt = Differential(t)
  Dx = Differential(x)
  Dxx = Differential(x)^2

  δρₛ(x) = δρ₀*exp(complex(0,1)*k*x);
#+end_src

#+RESULTS:

#+begin_src julia :session main :result output
  δρₛ(1)
#+end_src

#+RESULTS:
: 0.01999644704761618 + 0.0003769687943081636im


 $V(\rho) = v_h * (1 + e^{\frac{(\rho - \rho_h)}{\tau}})^{-1} + \delta{v}$

#+begin_src julia :session main :result output :tangle neuralPDE.jl
  #2D PDE
  eqs  = [Dt(v(t,x)) + v(t,x)*Dx(v(t,x)) - (μ/ρ(t,x))*Dxx(v(t,x)) + (c₀^2/ρ(t,x))*Dx(ρ(t,x)) - (vₕ*((1+exp((ρ(t,x)-ρₕ)/τ))^-1 - 3.72*10^-6) - v(t,x))/τ ~ 0,
          Dt(ρ(t,x)) + Dx(ρ(t,x)*v(t,x)) ~ 0]
#+end_src

#+RESULTS:

#+begin_src julia :session main :result output  :tangle neuralPDE.jl
  # Initial and boundary conditions
  bcs = [ρ(t,0) ~ ρ(t,L),
         v(t,0) ~ v(t,L),
         Dt(v(t,0)) ~ Dt(v(t,L)),
         max(ρ(t,x)) ~ ρₕ,
         ρ(0,x) ~ ρₕ +  0.02,
         v(0,x) ~ vₕ]

  # Space and time domains
  domains = [t ∈ Interval(0.0,3000.0),
             x ∈ Interval(0.0,L)]

  # Discretization
  dx = 0.1
#+end_src

#+RESULTS:
: 0.1

*** Workinng
#+begin_src julia :session main :result output :tangle neuralPDE.jl 
# Neural network
  input_ = length(domains)
  n = 15
  # Neural network
  dim = 2 # number of dimensions
  chain = FastChain(FastDense(dim,16,Flux.σ),FastDense(16,16,Flux.σ),FastDense(16,1))
#+end_src

#+RESULTS:
: FastChain{Tuple{FastDense{typeof(σ), DiffEqFlux.var"#initial_params#90"{Vector{Float32}}}, FastDense{typeof(σ), DiffEqFlux.var"#initial_params#90"{Vector{Float32}}}, FastDense{typeof(identity), DiffEqFlux.var"#initial_params#90"{Vector{Float32}}}}}((FastDense{typeof(σ), DiffEqFlux.var"#initial_params#90"{Vector{Float32}}}(16, 2, NNlib.σ, DiffEqFlux.var"#initial_params#90"{Vector{Float32}}(Float32[-0.26120892, -0.40437785, -0.0020874778, 0.24080808, -0.37667763, 0.06873026, 0.5229261, 0.14368661, -0.48830974, -0.2511761, -0.10650748, -0.06464203, -0.15838127, -0.38039255, -0.0049336883, 0.25456575, -0.5003041, -0.23945896, 0.026081016, -0.42371547, 0.46226588, -0.41744038, 0.36682677, 0.15965798, 0.29383457, -0.45507085, 0.37517422, -0.49152884, 0.56249166, 0.24415603, 0.5073206, 0.07076034, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]), true), FastDense{typeof(σ), DiffEqFlux.var"#initial_params#90"{Vector{Float32}}}(16, 16, NNlib.σ, DiffEqFlux.var"#initial_params#90"{Vector{Float32}}(Float32[-0.21968226, -0.028306283, 0.31565753, -0.16281894, 0.059859306, -0.17405538, 0.08420186, -0.15238619, -0.20570236, -0.011506525, 0.038236566, -0.06026627, 0.222046, -0.12506615, -0.06695941, -0.22243635, 0.20014721, 0.10488337, 0.3592894, 0.19525021, 0.016724393, -0.09632275, -0.40901113, -0.24151582, -0.3388284, -0.29834685, -0.32655722, 0.1262379, -0.3602354, -0.40855297, 0.30372348, -0.27957687, -0.16891465, -0.19332512, -0.3328599, 0.219862, -0.12571128, -0.017499506, -0.11505699, -0.33564, -0.24613336, -0.40788397, -0.41374832, -0.2983363, -0.36750686, 0.1889662, 0.26456955, -0.1847802, -0.15154749, -0.43223706, 0.25607148, 0.11206587, -0.2908543, -0.26943505, -0.3503042, 0.18155545, -0.3940894, -0.33743232, -0.29171893, -0.0752576, -0.3448275, -0.15899912, 0.22034444, 0.28238857, -0.0050883046, 0.23988837, -0.383773, 0.40915236, -0.097903535, 0.32994497, -0.36952695, 0.20405199, 0.42241693, -0.0022445032, -0.14115986, 0.22219323, 0.15098679, -0.15412349, 0.23417918, -0.23694731, 0.23446888, -0.2188893, 0.17442364, 0.108865686, -0.075207844, -0.42182145, -0.06639656, 0.23855205, 0.10375756, 0.1622982, 0.40282902, -0.27059957, -0.07363759, -0.014485259, -0.23703167, -0.21711081, 0.026493419, 0.010926738, -0.35743165, 0.10470219, 0.10917261, -0.04478951, 0.07900701, 0.36878362, -0.107787155, -0.16236375, 0.3878346, -0.20545758, 0.31358862, 0.3478663, -0.03195813, 0.067946576, 0.42031944, 0.14850423, 0.19087178, -0.24545993, 0.36464605, -0.23786892, -0.13879931, 0.34713733, -0.28771186, 0.008234904, 0.0064235884, 0.43202728, -0.11956334, -0.33935317, 0.35648277, -0.24903415, 0.07129635, 0.08176316, 0.25887924, 0.009871334, -0.14553571, 0.19668584, 0.12522018, -0.23411663, 0.11980667, -0.04695545, 0.24957965, -0.40714574, 0.10449262, -0.1353429, 0.13892175, -0.4178435, -0.14133753, -0.02783531, -0.22241312, -0.26052105, 0.36464965, -0.11723759, 0.3187267, 0.12567091, 0.09067025, 0.36545047, 0.0015596206, -0.19303843, 0.21183264, 0.08936862, 0.008111947, -0.22773919, -0.2698735, -0.17970005, 0.2868333, -0.08406404, 0.13359188, -0.06841125, 0.052824028, 0.25355557, -0.12876797, -0.115824774, -0.172857, -0.052412007, -0.2567611, -0.2447542, -0.349747, 0.12584601, -0.026370358, 0.3366351, 0.23944774, -0.32551152, 0.17125227, 0.24369632, 0.12124034, 0.027506083, 0.22831629, 0.31739253, 0.10408183, -0.21757579, 0.39604566, -0.10280044, 0.25740182, 0.06626338, 0.038711563, -0.10972494, -0.07341604, 0.084753975, 0.18417749, -0.36312503, 0.15346028, -0.18656643, -0.39335114, 0.18789127, -0.007658525, 0.22263281, 0.22798707, -0.22922334, 0.04305201, -0.040705923, -0.14498164, 0.12167394, -0.34423944, -0.1566488, -0.10012378, -0.29490682, 0.24791008, -0.13950525, -0.1046229, 0.1964293, 0.32606083, -0.18514669, -0.3649637, -0.09354368, 0.35328, 0.37297705, -0.056786004, -0.09781, 0.32532898, 0.10067538, 0.33115223, -0.1890078, -0.3524157, -0.30053517, -0.111314185, 0.29200563, -0.22519457, 0.3491418, -0.394954, 0.32234365, -0.22691287, -0.29151082, -0.21297044, -0.17279433, -0.42688456, 0.3817298, -0.32040298, 0.41783047, -0.39573655, 0.2567417, 0.12019681, -0.03617304, -0.005711967, 0.054798357, 0.061278727, -0.020183908, 0.29797012, 0.3820412, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]), true), FastDense{typeof(identity), DiffEqFlux.var"#initial_params#90"{Vector{Float32}}}(1, 16, identity, DiffEqFlux.var"#initial_params#90"{Vector{Float32}}(Float32[-0.59139353, -0.5890274, -0.2814471, -0.32830885, 0.069460265, 0.118930206, 0.5335248, -0.16907379, 0.26307717, -0.5178469, 0.5252732, 0.24326362, -0.20021415, 0.38461033, 0.23408099, 0.39774376, 0.0]), true)))

#+begin_src julia :session main :result output :tangle neuralPDE.jl
  discretization = PhysicsInformedNN(chain, QuadratureTraining()) 
#+end_src

#+RESULTS:
: Output suppressed (line too long)

#+begin_src julia :session main :result output :tangle neuralPDE.jl
  pde_system = PDESystem(eqs,bcs,domains,[t,x],[v,ρ])
#+end_src

#+RESULTS:

#+begin_src julia :session main :result output :tangle neuralPDE.jl
  prob = discretize(pde_system,discretization)
#+end_src

#+RESULTS:

#+begin_src julia :session main :result output :tangle neuralPDE.jl
  cb = function (p,l)
      println("Current loss is: $l")
      return false
  end
  
  res = GalacticOptim.solve(prob, ADAM(0.1); cb = cb, maxiters=100)
  prob = remake(prob,u0=res.minimizer)
  res = GalacticOptim.solve(prob, ADAM(0.1); cb = cb, maxiters=100)
  phi = discretization.phi
#+end_src

#+RESULTS:

#+begin_src julia :session main :result output :tangle neuralPDE.jl
using Plots
#+end_src

#+RESULTS:

#+begin_src julia :session main :result output
  ts,xs = [infimum(d.domain):dx:supremum(d.domain) for d in domains]
  v_predict_contourf = reshape([first(phi([t,x],res.minimizer)) for t in ts for x in xs] ,length(xs),length(ts))
  plot(ts, xs, v_predict_contourf, linetype=:contourf,title = "predict")
  
  v_predict = [[first(phi([t,x],res.minimizer)) for x in xs] for t in ts ]
  ρ_predict = [[second(phi([t,x],res.minimizer)) for x in xs] for t in ts ]
  
  p1= plot(xs, v_predict[3],title = "t = 0.1");
  p2= plot(xs, v_predict[11],title = "t = 0.5");
  p3= plot(xs, v_predict[end],title = "t = 1");
  plot(p1,p2,p3)
#+end_src

#+RESULTS:

*** Tests
#+begin_src julia :session main :result output :tangle neuralPDE.jl
# Neural network
  input_ = length(domains)
  n = 5
  chain =[FastChain(FastDense(input_,n,Flux.σ),FastDense(n,n,Flux.σ),FastDense(n,1)) for _ in 1:2]
  initθ = map(c -> Float64.(c), DiffEqFlux.initial_params.(chain))
  flat_initθ = reduce(vcat,initθ)
  
  eltypeθ = eltype(initθ[1])
  parameterless_type_θ = DiffEqBase.parameterless_type(initθ[1])
  phi = NeuralPDE.get_phi.(chain,parameterless_type_θ)
  
  map(phi_ -> phi_(rand(2,10), flat_initθ),phi)
  
  derivative = NeuralPDE.get_numeric_derivative()
#+end_src

#+RESULTS:

#+begin_src julia :session main :result output :tangle neuralPDE.jl 
  # :tangle neuralPDE.jl
    indvars = [t,x]
    depvars = [v,ρ]
    dim = length(domains)
    quadrature_strategy = NeuralPDE.QuadratureTraining()


    _pde_loss_functions = [NeuralPDE.build_loss_function(eq,indvars,depvars,phi,derivative,
                                                         chain,initθ,quadrature_strategy) for eq in  eqs]

    map(loss_f -> loss_f(rand(2,10), flat_initθ),_pde_loss_functions)

    bc_indvars = NeuralPDE.get_argument(bcs,indvars,depvars)
    _bc_loss_functions = [NeuralPDE.build_loss_function(bc,indvars,depvars, phi, derivative,
                                                        chain,initθ,quadrature_strategy,
                                                        bc_indvars = bc_indvar) for (bc,bc_indvar) in zip(bcs,bc_indvars)]
    map(loss_f -> loss_f(rand(1,10), flat_initθ),_bc_loss_functions)

#+end_src

#+RESULTS:

#+begin_src julia :session main :result output :tangle neuralPDE.jl
  # dx = 0.1
  # train_sets = NeuralPDE.generate_training_sets(domains,dx,eqs,bcs,eltypeθ,indvars,depvars)
  # pde_train_set,bcs_train_set = train_sets
  pde_bounds, bcs_bounds = NeuralPDE.get_bounds(domains,eqs,bcs,eltypeθ,indvars,depvars,quadrature_strategy)
  
  plbs,pubs = pde_bounds
  pde_loss_functions = [NeuralPDE.get_loss_function(_loss,
                                                   lb,ub,
                                                   eltypeθ, parameterless_type_θ,
                                                   quadrature_strategy)
                                                   for (_loss,lb,ub) in zip(_pde_loss_functions, plbs,pubs)]
  
  map(l->l(flat_initθ) ,pde_loss_functions)
  
  blbs,bubs = bcs_bounds
  bc_loss_functions = [NeuralPDE.get_loss_function(_loss,lb,ub,
                                                   eltypeθ, parameterless_type_θ,
                                                   quadrature_strategy)
                                                   for (_loss,lb,ub) in zip(_bc_loss_functions, blbs,bubs)]
  
  map(l->l(flat_initθ) ,bc_loss_functions)
  
  loss_functions =  [pde_loss_functions;bc_loss_functions]
  
  function loss_function(θ,p)
      sum(map(l->l(θ) ,loss_functions))
  end
  
  f_ = OptimizationFunction(loss_function, GalacticOptim.AutoZygote())
  prob = GalacticOptim.OptimizationProblem(f_, flat_initθ)
  
  cb_ = function (p,l)
      println("loss: ", l )
      println("pde losses: ", map(l -> l(p), loss_functions[1:2]))
      println("bcs losses: ", map(l -> l(p), loss_functions[3:end]))
      return false
  end
  
  res = GalacticOptim.solve(prob,Optim.BFGS(); cb = cb_, maxiters=5)
#+end_src

#+RESULTS:

#+begin_src julia :session main :result output :tangle neuralPDE.jl
using Plots
#+end_src

#+RESULTS:
: nothing

#+begin_src julia :session main :result output :tangle neuralPDE.jl
ts,xs = [infimum(d.domain):0.1:supremum(d.domain) for d in domains]

acum =  [0;accumulate(+, length.(initθ))]
sep = [acum[i]+1 : acum[i+1] for i in 1:length(acum)-1]
minimizers_ = [res.minimizer[s] for s in sep]

u_predict  = [[phi[i]([t,x],minimizers_[i])[1] for t in ts  for x in xs] for i in 1:2]
#+end_src

#+RESULTS:


#+begin_src julia :session main :result output :tangle neuralPDE.jl
  for i in 1:2
      p1 = plot(ts, xs, u_predict[i],linetype=:contourf,title = "predict$i");
      plot(p1)
      savefig("sol_variablee$i")
  end
#+end_src

#+RESULTS:


