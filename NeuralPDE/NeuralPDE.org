#+STARTUP: latexpreview
#+STARTUP: inlineimages


* The equation to solve:
\begin{equation}
\begin{aligned}
\begin{cases}
\label{eq:NS-n1}
\left[\frac{\partial{v}}{\partial{t}} + v\frac{\partial{v}}{\partial{x}} \right] = \frac{1}{\rho{}}\dfrac{\partial \left(\mu \frac{\partial{v}}{\partial{x}} \right)}{\partial{x}} - \left(\frac{c_0^2}{\rho{}}\right)\dfrac{\partial{\rho}}{\partial{x}} + \frac{V(\rho) - v}{\tau} \\\\
     \dfrac{\partial{\rho}}{\partial{t}} + \dfrac{\partial{\left( \rho{}v \right)}}{\partial{x}}=0
\end{cases}
   \end{aligned}
 \end{equation}

\begin{equation}
\begin{aligned}
q(x,t)=\rho(x,t)v(x,t)
\end{aligned}
\end{equation}

* Boundary Conditions:
\begin{equation}
\begin{aligned}
q(0,t) &= q(L,t)\\
v(0,t) &= v(L,t),\quad \dfrac{\partial{v}}{\partial{x}}\biggr\rvert_0 = \dfrac{\partial{v}}{\partial{x}}\biggr\rvert_L  
\end{aligned}
\end{equation}

From the definition of $q$ and the boundary condition (I),
\begin{equation}
\begin{aligned}
&\rho(0,t)v(0,t) = \rho(L,t)v(L,t) \\
&\implies \rho(0,t) = \rho(L,t)
\end{aligned}
\end{equation}

* Examples from NeuralPDE.jl
** System of PDEs

#+begin_src julia :session main :result output
  using NeuralPDE, Flux, ModelingToolkit, GalacticOptim, Optim, DiffEqFlux
  using Quadrature,Cubature
  import ModelingToolkit: Interval, infimum, supremum

  @parameters t, x
  @variables u1(..), u2(..), u3(..)
  Dt = Differential(t)
  Dtt = Differential(t)^2
  Dx = Differential(x)
  Dxx = Differential(x)^2

  eqs = [Dtt(u1(t,x)) ~ Dxx(u1(t,x)) + u3(t,x)*sin(pi*x),
         Dtt(u2(t,x)) ~ Dxx(u2(t,x)) + u3(t,x)*cos(pi*x),
         0. ~ u1(t,x)*sin(pi*x) + u2(t,x)*cos(pi*x) - exp(-t)]

  bcs = [u1(0,x) ~ sin(pi*x),
         u2(0,x) ~ cos(pi*x),
         Dt(u1(0,x)) ~ -sin(pi*x),
         Dt(u2(0,x)) ~ -cos(pi*x),
         u1(t,0) ~ 0.,
         u2(t,0) ~ exp(-t),
         u1(t,1) ~ 0.,
         u2(t,1) ~ -exp(-t)]


  # Space and time domains
  domains = [t ∈ Interval(0.0,1.0),
             x ∈ Interval(0.0,1.0)]

  # Neural network
  input_ = length(domains)
  n = 15
  chain =[FastChain(FastDense(input_,n,Flux.σ),FastDense(n,n,Flux.σ),FastDense(n,1)) for _ in 1:3]
  initθ = map(c -> Float64.(c), DiffEqFlux.initial_params.(chain))

  _strategy = QuadratureTraining()
  discretization = PhysicsInformedNN(chain, _strategy, init_params= initθ)

  pde_system = PDESystem(eqs,bcs,domains,[t,x],[u1,u2,u3])
  prob = discretize(pde_system,discretization)
  sym_prob = symbolic_discretize(pde_system,discretization)

  pde_inner_loss_functions = prob.f.f.loss_function.pde_loss_function.pde_loss_functions.contents
  bcs_inner_loss_functions = prob.f.f.loss_function.bcs_loss_function.bc_loss_functions.contents

  cb = function (p,l)
      println("loss: ", l )
      println("pde_losses: ", map(l_ -> l_(p), pde_inner_loss_functions))
      println("bcs_losses: ", map(l_ -> l_(p), bcs_inner_loss_functions))
      return false
  end

  res = GalacticOptim.solve(prob,BFGS(); cb = cb, maxiters=5000)

  phi = discretization.phi
#+end_src

#+RESULTS:

#+begin_src julia :session main :result output
xs,ys = [infimum(domain):dx/10:domain.domain.upper for domain in domains]
analytic_sol_func(x,y) = (sin(pi*x)*sin(pi*y))/(2pi^2)

u_predict = reshape([first(phi([x,y],res.minimizer)) for x in xs for y in ys],(length(xs),length(ys)))
u_real = reshape([analytic_sol_func(x,y) for x in xs for y in ys], (length(xs),length(ys)))
diff_u = abs.(u_predict .- u_real)

using Plots
p1 = plot(xs, ys, u_real, linetype=:contourf,title = "analytic");
p2 = plot(xs, ys, u_predict, linetype=:contourf,title = "predict");
p3 = plot(xs, ys, diff_u,linetype=:contourf,title = "error");
plot(p1,p2,p3)
#+end_src

#+RESULTS:

* Kerner - Car Flow

# Let $V(\rho)=1.5*(1-p/\hat{p})^2$, so $p \to \hat{\rho} \implies V(\hat{\rho}) \to 0$.
Let, $V(\rho) = v_h * (e^{-\frac{(\rho - \rho_h)}{\tau}}) + \delta{v}$.

#+begin_src julia :session main :result output :tangle neuralPDE.jl
  using NeuralPDE, Flux, ModelingToolkit, GalacticOptim, Optim, DiffEqFlux
  import ModelingToolkit: Interval, infimum, supremum
  import Flux: flatten, params
#+end_src

#+RESULTS:
: nothing

# #+begin_src julia :session main :result output
#   #V(ρ)=1.5*(1-ρ/2)²;
#   @parameters t, x, μ, c₀, τ, L, l
#   @variables v(..), ρ(..)
#   μ=0.3;
#   c₀= sqrt(5.5);
#   τ = 0.02;
#   l=0.08;
#   L = 100.0;
#   Dt = Differential(t)
#   Dx = Differential(x)
#   Dxx = Differential(x)^2
# #+end_src

# #+RESULTS:

 $V(\rho) = v_h * (e^{-\frac{(\rho - \rho_h)}{\tau}}) + \delta{v}$

Let's put as a condition that $[-1 -\frac{\rho_h}{c_0}\xi(\rho_h)]\rho_h>(\frac{2\pi{}l}{L})^2$ in which $\xi(\rho_h)= \dfrac{dV(\rho_h)}{dt}$

\begin{equation}
\begin{aligned}
\dfrac{dV(\rho_h)}{dt}= \dfrac{v_h (\rho - \rho_h)}{\tau^2}(e^{-\frac{(\rho - \rho_h)}{\tau}})
\end{aligned}
\end{equation}

#+begin_src julia :session main :result output :tangle neuralPDE.jl
  @parameters t, x, N, L, ρ_hat, μ, c₀, τ, L, l,vₕ, k,m
  @variables v(..), ρ(..)
  ρ_hat=0.89;
  m=1;
  μ=1; #choose as we like
  τ=1; #choose as we like 
  l=sqrt(μ*τ/ρ_hat);

  N = 168; 
  ρₕ = 0.168;
  L=N/ρₕ; 
  δρ₀ = 0.02;
  vₕ = 5.0461*((1+exp((ρₕ-0.25)/0.06))^-1 - 3.72*10^-6);

  # ρₕ=N/L;
  k=2π*3/L;

  c₀= 1.8634; 
  Dt = Differential(t)
  Dx = Differential(x)
  Dxx = Differential(x)^2

  δρₛ(x) = δρ₀*exp(complex(0,1)*k*x);
#+end_src

#+RESULTS:
: δρₛ

#+begin_src julia :session main :result output
  δρₛ(1)
#+end_src

#+RESULTS:
: 0.01999644704761618 + 0.0003769687943081636im


 $V(\rho) = v_h * (1 + e^{\frac{(\rho - \rho_h)}{\tau}})^{-1} + \delta{v}$

#+begin_src julia :session main :result output :tangle neuralPDE.jl
  #2D PDE
  eqs  = [Dt(v(t,x)) + v(t,x)*Dx(v(t,x)) - (μ/ρ(t,x))*Dxx(v(t,x)) + (c₀^2/ρ(t,x))*Dx(ρ(t,x)) - (vₕ*((1+exp((ρ(t,x)-ρₕ)/τ))^-1 - 3.72*10^-6) - v(t,x))/τ ~ 0,
          Dt(ρ(t,x)) + Dx(ρ(t,x)*v(t,x)) ~ 0]
#+end_src

#+RESULTS:
: Equation[1.4957825932269718e-5 + Differential(t)(v(t, x)) + v(t, x) + Differential(x)(v(t, x))*v(t, x) + 3.47225956Differential(x)(ρ(t, x))*(ρ(t, x)^-1) - (4.020920949534869((1 + exp(ρ(t, x) - 0.168))^-1)) - (Differential(x)(Differential(x)(v(t, x)))*(ρ(t, x)^-1)) ~ 0, Differential(t)(ρ(t, x)) + Differential(x)(v(t, x)*ρ(t, x)) ~ 0]

#+begin_src julia :session main :result output  :tangle neuralPDE.jl
  # Initial and boundary conditions
  bcs = [ρ(t,0) ~ ρ(L,0),
         v(t,0) ~ v(t,L),
         Dt(v(t,0)) ~ Dt(v(t,L)),
         max(ρ(t,x)) ~ ρₕ,
         ρ(0,x) ~ ρₕ +  0.02,
         v(0,x) ~ vₕ]

  # Space and time domains
  domains = [t ∈ Interval(0.0,3000.0),
             x ∈ Interval(0.0,L)]

  # Discretization
  dx = 0.1
#+end_src

#+RESULTS:
: 0.1

*** Workinng
#+begin_src julia :session main :result output :tangle neuralPDE.jl 
# Neural network
  input_ = length(domains)
  n = 15
  # Neural network
  dim = 2 # number of dimensions
  chain = FastChain(FastDense(dim,16,Flux.σ),FastDense(16,16,Flux.σ),FastDense(16,1))
#+end_src

#+RESULTS:

#+begin_src julia :session main :result output :tangle neuralPDE.jl
  discretization = PhysicsInformedNN(chain, QuadratureTraining()) 
#+end_src

#+RESULTS:
: Output suppressed (line too long)

#+begin_src julia :session main :result output :tangle neuralPDE.jl
  pde_system = PDESystem(eqs,bcs,domains,[t,x],[v,ρ])
#+end_src

#+RESULTS:

#+begin_src julia :session main :result output :tangle neuralPDE.jl
  prob = discretize(pde_system,discretization)
#+end_src

#+RESULTS:

#+begin_src julia :session main :result output :tangle neuralPDE.jl
  cb = function (p,l)
      println("Current loss is: $l")
      return false
  end
  
  res = GalacticOptim.solve(prob, ADAM(0.1); cb = cb, maxiters=100)
  prob = remake(prob,u0=res.minimizer)
  res = GalacticOptim.solve(prob, ADAM(0.1); cb = cb, maxiters=100)
  phi = discretization.phi
#+end_src

#+RESULTS:

#+begin_src julia :session main :result output :tangle neuralPDE.jl
using Plots
#+end_src

#+RESULTS:
: nothing

#+begin_src julia :session main :result output
  ts,xs = [infimum(d.domain):dx:supremum(d.domain) for d in domains]
  v_predict_contourf = reshape([first(phi([t,x],res.minimizer)) for t in ts for x in xs] ,length(xs),length(ts))
  plot(ts, xs, v_predict_contourf, linetype=:contourf,title = "predict")
  
  v_predict = [[first(phi([t,x],res.minimizer)) for x in xs] for t in ts ]
  ρ_predict = [[second(phi([t,x],res.minimizer)) for x in xs] for t in ts ]
  
  p1= plot(xs, v_predict[3],title = "t = 0.1");
  p2= plot(xs, v_predict[11],title = "t = 0.5");
  p3= plot(xs, v_predict[end],title = "t = 1");
  plot(p1,p2,p3)
#+end_src

#+RESULTS:

*** Tests
#+begin_src julia :session main :result output :tangle neuralPDE.jl
# Neural network
  input_ = length(domains)
  n = 5
  chain =[FastChain(FastDense(input_,n,Flux.σ),FastDense(n,n,Flux.σ),FastDense(n,1)) for _ in 1:2]
  initθ = map(c -> Float64.(c), DiffEqFlux.initial_params.(chain))
  flat_initθ = reduce(vcat,initθ)
  
  eltypeθ = eltype(initθ[1])
  parameterless_type_θ = DiffEqBase.parameterless_type(initθ[1])
  phi = NeuralPDE.get_phi.(chain,parameterless_type_θ)
  
  map(phi_ -> phi_(rand(2,10), flat_initθ),phi)
  
  derivative = NeuralPDE.get_numeric_derivative()
#+end_src

#+RESULTS:

#+begin_src julia :session main :result output :tangle neuralPDE.jl 
  # :tangle neuralPDE.jl
    indvars = [t,x]
    depvars = [v,ρ]
    dim = length(domains)
    quadrature_strategy = NeuralPDE.QuadratureTraining()


    _pde_loss_functions = [NeuralPDE.build_loss_function(eq,indvars,depvars,phi,derivative,
                                                         chain,initθ,quadrature_strategy) for eq in  eqs]

    map(loss_f -> loss_f(rand(2,10), flat_initθ),_pde_loss_functions)

    bc_indvars = NeuralPDE.get_argument(bcs,indvars,depvars)
    _bc_loss_functions = [NeuralPDE.build_loss_function(bc,indvars,depvars, phi, derivative,
                                                        chain,initθ,quadrature_strategy,
                                                        bc_indvars = bc_indvar) for (bc,bc_indvar) in zip(bcs,bc_indvars)]
    map(loss_f -> loss_f(rand(1,10), flat_initθ),_bc_loss_functions)

#+end_src

#+RESULTS:

#+begin_src julia :session main :result output :tangle neuralPDE.jl
  # dx = 0.1
  # train_sets = NeuralPDE.generate_training_sets(domains,dx,eqs,bcs,eltypeθ,indvars,depvars)
  # pde_train_set,bcs_train_set = train_sets
  pde_bounds, bcs_bounds = NeuralPDE.get_bounds(domains,eqs,bcs,eltypeθ,indvars,depvars,quadrature_strategy)
  
  plbs,pubs = pde_bounds
  pde_loss_functions = [NeuralPDE.get_loss_function(_loss,
                                                   lb,ub,
                                                   eltypeθ, parameterless_type_θ,
                                                   quadrature_strategy)
                                                   for (_loss,lb,ub) in zip(_pde_loss_functions, plbs,pubs)]
  
  map(l->l(flat_initθ) ,pde_loss_functions)
  
  blbs,bubs = bcs_bounds
  bc_loss_functions = [NeuralPDE.get_loss_function(_loss,lb,ub,
                                                   eltypeθ, parameterless_type_θ,
                                                   quadrature_strategy)
                                                   for (_loss,lb,ub) in zip(_bc_loss_functions, blbs,bubs)]
  
  map(l->l(flat_initθ) ,bc_loss_functions)
  
  loss_functions =  [pde_loss_functions;bc_loss_functions]
  
  function loss_function(θ,p)
      sum(map(l->l(θ) ,loss_functions))
  end
  
  f_ = OptimizationFunction(loss_function, GalacticOptim.AutoZygote())
  prob = GalacticOptim.OptimizationProblem(f_, flat_initθ)
  
  cb_ = function (p,l)
      println("loss: ", l )
      println("pde losses: ", map(l -> l(p), loss_functions[1:2]))
      println("bcs losses: ", map(l -> l(p), loss_functions[3:end]))
      return false
  end
  
  res = GalacticOptim.solve(prob,Optim.BFGS(); cb = cb_, maxiters=5)
#+end_src

#+RESULTS:

#+begin_src julia :session main :result output :tangle neuralPDE.jl
using Plots
#+end_src

#+RESULTS:
: nothing

#+begin_src julia :session main :result output :tangle neuralPDE.jl
ts,xs = [infimum(d.domain):0.1:supremum(d.domain) for d in domains]

acum =  [0;accumulate(+, length.(initθ))]
sep = [acum[i]+1 : acum[i+1] for i in 1:length(acum)-1]
minimizers_ = [res.minimizer[s] for s in sep]

u_predict  = [[phi[i]([t,x],minimizers_[i])[1] for t in ts  for x in xs] for i in 1:2]
#+end_src

#+RESULTS:


#+begin_src julia :session main :result output :tangle neuralPDE.jl
  for i in 1:2
      p1 = plot(ts, xs, u_predict[i],linetype=:contourf,title = "predict$i");
      plot(p1)
      savefig("sol_variablee$i")
  end
#+end_src

#+RESULTS:


